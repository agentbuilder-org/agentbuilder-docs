---
title: 'Models'
description: 'Configure LLM models with fallbacks and pricing tracking'
---

## What are Models?

Models in Standard Agents define the LLM configurations that your agents and prompts use for AI responses. Each model configuration specifies which provider to use, the specific model ID, fallback models for resilience, and pricing for cost tracking.

<Card title="Key Benefits" icon="brain">
  - **Provider flexibility**: Support for OpenAI, Anthropic, Google, and OpenRouter
  - **Automatic fallbacks**: Retry with backup models when primary fails
  - **Cost tracking**: Track token usage and costs across your application
  - **Type-safe references**: Auto-generated types prevent typos
</Card>

## Why Models?

Instead of hardcoding model strings throughout your codebase, Standard Agents uses centralized model definitions that provide:

1. **Reusability**: Define once, reference everywhere
2. **Consistency**: Same model configuration across all prompts
3. **Resilience**: Automatic retry with fallback models
4. **Visibility**: Track costs and usage per model

## Quick Example

```typescript agents/models/gpt_4o.ts
import { defineModel } from '@standardagents/builder';

export default defineModel({
  name: 'gpt-4o',
  provider: 'openai',
  model: 'gpt-4o',
  inputPrice: 2.5,
  outputPrice: 10,
});
```

Reference in a prompt:

```typescript agents/prompts/my_prompt.ts
import { definePrompt } from '@standardagents/builder';

export default definePrompt({
  name: 'my_prompt',
  model: 'gpt-4o',  // Type-safe reference
  prompt: 'You are a helpful assistant...',
});
```

## Model Providers

<CardGroup cols={2}>
  <Card title="OpenAI" icon="openai">
    GPT-4o, GPT-4 Turbo, o1-mini, and more
  </Card>
  <Card title="Anthropic" icon="robot">
    Claude 4 Sonnet, Claude 3 Opus, Haiku
  </Card>
  <Card title="Google" icon="google">
    Gemini 1.5 Pro, Gemini Flash
  </Card>
  <Card title="OpenRouter" icon="route">
    Access multiple providers through one API
  </Card>
</CardGroup>

### OpenAI

```typescript
defineModel({
  name: 'gpt-4o',
  provider: 'openai',
  model: 'gpt-4o',
  inputPrice: 2.5,
  outputPrice: 10,
});
```

**Available models:**
- `gpt-4o` - Most capable, multimodal
- `gpt-4-turbo` - Previous generation flagship
- `gpt-4o-mini` - Faster, cheaper alternative
- `gpt-3.5-turbo` - Legacy model
- `o1-mini`, `o1-preview` - Reasoning models

**API Key:** Set `OPENAI_API_KEY` environment variable

### Anthropic

```typescript
defineModel({
  name: 'claude-sonnet',
  provider: 'anthropic',
  model: 'claude-sonnet-4-20250514',
  inputPrice: 3,
  outputPrice: 15,
});
```

**Available models:**
- `claude-sonnet-4-20250514` - Latest Sonnet
- `claude-3-opus-20240229` - Most capable
- `claude-3-sonnet-20240229` - Balanced performance
- `claude-3-haiku-20240307` - Fast and efficient

**API Key:** Set `ANTHROPIC_API_KEY` environment variable

### OpenRouter

OpenRouter provides access to models from multiple providers through a single API:

```typescript
defineModel({
  name: 'openrouter-claude',
  provider: 'openrouter',
  model: 'anthropic/claude-sonnet-4.5',
  includedProviders: ['anthropic'],  // Optional: prefer specific providers
});
```

**Model ID format:** `provider/model-name`

**Example models:**
- `openai/gpt-4o`
- `anthropic/claude-3-opus`
- `google/gemini-pro`
- `meta-llama/llama-2-70b-chat`

**API Key:** Set `OPENROUTER_API_KEY` environment variable

### Google

```typescript
defineModel({
  name: 'gemini-pro',
  provider: 'google',
  model: 'gemini-1.5-pro',
  inputPrice: 1.25,
  outputPrice: 5,
});
```

**Available models:**
- `gemini-1.5-pro` - Most capable
- `gemini-1.5-flash` - Fast and efficient
- `gemini-pro` - Previous generation

**API Key:** Set `GOOGLE_API_KEY` environment variable

## Fallback Models

Fallback models provide resilience when the primary model is unavailable or fails. The system automatically retries with fallback models for:

- Network errors
- Rate limits (429)
- Server errors (5xx)
- Authentication errors (401)

```typescript
defineModel({
  name: 'primary-model',
  provider: 'openai',
  model: 'gpt-4o',
  fallbacks: ['fallback-1', 'fallback-2'],  // Try these if primary fails
});
```

### Retry Sequence

When a request fails:

1. **Primary model** (attempt 1) → Failed? Retry...
2. **Primary model** (attempt 2) → Failed? Try fallback...
3. **Fallback 1** (attempt 1) → Failed? Retry...
4. **Fallback 1** (attempt 2) → Failed? Try next fallback...
5. **Fallback 2** (attempt 1) → Failed? Retry...
6. **Fallback 2** (attempt 2) → Failed? Throw error

<Tip>
  Configure fallbacks for production deployments to ensure high availability. Choose fallback models from different providers to avoid provider-specific outages.
</Tip>

## Pricing Configuration

Configure pricing to track token costs across your application:

```typescript
defineModel({
  name: 'gpt-4o',
  provider: 'openai',
  model: 'gpt-4o',
  inputPrice: 2.5,    // $2.50 per 1M input tokens
  outputPrice: 10,    // $10 per 1M output tokens
  cachedPrice: 1.25,  // $1.25 per 1M cached tokens (if provider supports)
});
```

**Pricing units:** All prices are in USD per 1 million tokens

### Current Pricing Examples

| Model | Input Price | Output Price |
|-------|-------------|--------------|
| GPT-4o | $2.50 | $10.00 |
| GPT-4o-mini | $0.15 | $0.60 |
| Claude 3 Opus | $15.00 | $75.00 |
| Claude 3 Sonnet | $3.00 | $15.00 |
| Claude 3 Haiku | $0.25 | $1.25 |
| Gemini 1.5 Pro | $1.25 | $5.00 |
| Gemini 1.5 Flash | $0.075 | $0.30 |

<Note>
  Prices shown are as of 2024 and may change. Check provider websites for current pricing.
</Note>

## Type Safety

After defining models, Standard Agents generates the `StandardAgents.Models` type:

```typescript
// Auto-generated
declare namespace StandardAgents {
  type Models = 'gpt-4o' | 'claude-sonnet' | 'gemini-pro' | /* ... */;
}
```

This enables type-safe model references in prompts:

```typescript
definePrompt({
  name: 'my_prompt',
  model: 'gpt-4o',  // TypeScript validates this
  // model: 'typo',  // ❌ Error: not a valid model
  // ...
});
```

## Common Patterns

### Cost-Optimized Chain

Use cheaper models with expensive fallbacks:

```typescript
// Primary: Fast and cheap
defineModel({
  name: 'budget-primary',
  provider: 'openai',
  model: 'gpt-4o-mini',
  fallbacks: ['claude-haiku', 'gemini-flash'],
  inputPrice: 0.15,
  outputPrice: 0.60,
});
```

### High-Performance Chain

Use most capable models with reliable fallbacks:

```typescript
// Primary: Most capable
defineModel({
  name: 'high-performance',
  provider: 'anthropic',
  model: 'claude-3-opus-20240229',
  fallbacks: ['gpt-4o', 'gemini-pro'],
  inputPrice: 15,
  outputPrice: 75,
});
```

### Multi-Provider Resilience

Fallbacks from different providers for maximum uptime:

```typescript
defineModel({
  name: 'resilient-model',
  provider: 'openai',
  model: 'gpt-4o',
  fallbacks: [
    'claude-sonnet',    // Anthropic
    'gemini-pro',       // Google
    'openrouter-gpt',   // OpenRouter
  ],
});
```

## Environment Setup

Configure provider API keys as environment variables:

```bash .dev.vars
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# OpenRouter
OPENROUTER_API_KEY=sk-or-...

# Google
GOOGLE_API_KEY=...
```

For Cloudflare Workers, add to `wrangler.jsonc`:

```jsonc wrangler.jsonc
{
  "vars": {
    "OPENAI_API_KEY": "...",
    "ANTHROPIC_API_KEY": "..."
  }
}
```

Or use Cloudflare secrets for production:

```bash
wrangler secret put OPENAI_API_KEY
wrangler secret put ANTHROPIC_API_KEY
```

## File Organization

Models are auto-discovered from the `agents/models/` directory:

```
agents/
└── models/
    ├── gpt_4o.ts           # export default defineModel({...})
    ├── claude_sonnet.ts    # export default defineModel({...})
    ├── gemini_pro.ts       # export default defineModel({...})
    └── budget.ts           # export default defineModel({...})
```

**Requirements:**
- Use snake_case for file names: `gpt_4o.ts`, `claude_sonnet.ts`
- One model per file
- Default export required

## Next Steps

<CardGroup cols={2}>
  <Card title="Model API Reference" icon="code" href="/api-reference/models">
    Complete defineModel specification
  </Card>
  <Card title="Prompts" icon="message" href="/core-concepts/prompts">
    Learn how to use models in prompts
  </Card>
  <Card title="Getting Started" icon="rocket" href="/quickstart">
    Set up your first agent
  </Card>
  <Card title="Examples" icon="sparkles" href="/examples">
    See model configurations in action
  </Card>
</CardGroup>
